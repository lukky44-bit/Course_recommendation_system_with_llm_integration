# AI Course Recommendation System (MERN + FastAPI + Gemini LLM)

This project is a full-stack AI-powered course recommendation system. It combines NLP, BERT-based semantic search, a FastAPI backend, a professional Node.js/Express API server, and a modern HTML/CSS/JS frontend (with Gemini LLM integration for user queries).

---

## Project Description

This repository contains a full-stack AI-powered course recommendation system that leverages state-of-the-art NLP and large language models. Built with FastAPI (Python), Node.js/Express, MongoDB, and a modern HTML/CSS/JS frontend, the system provides personalized course recommendations and intelligent chat via Gemini LLM. The backend uses Sentence-BERT for semantic search, enabling users to find the most relevant courses based on natural language queries. User authentication, history tracking, and secure API key management are included. The project is production-ready, professionally documented, and features a clean, responsive UI inspired by modern SaaS dashboards.

---

## Project Structure & File Descriptions

```
my_recommender_api/
│
├── app.py                        # FastAPI backend for course recommendations (Python)
├── course_recommendation.ipynb   # Jupyter notebook: NLP, BERT, and embedding generation
├── course_title_embeddings.npy   # Precomputed course title embeddings (NumPy array)
├── udemy_course_data.csv         # Course dataset (CSV)
├── sentence_transformer_model/   # Saved Sentence-BERT model (for FastAPI and notebook)
│
├── mern/                        # MERN stack webapp (client + server)
│   ├── client/                  # Frontend (HTML/CSS/JS, not React)
│   │   ├── public/
│   │   │   ├── index.html       # Main frontend UI (login, register, recommend, Gemini LLM)
│   │   │   ├── style.css        # Professional CSS for the UI
│   │   │   ├── app.js           # Frontend logic (auth, recommend, Gemini chat)
│   │   └── ...                  # (No src/ needed; can be deleted)
│   ├── server/                  # Express backend (Node.js)
│   │   ├── index.js             # Express server, API proxy, Gemini LLM endpoint
│   │   ├── models/User.js       # Mongoose user schema
│   │   ├── .env                 # Environment variables (Mongo URI, Gemini API key)
│   │   └── ...
│   └── README.md                # (This file)
│
└── ...
```

---

## How the System Works

1. **NLP & Embeddings**: The Jupyter notebook (`course_recommendation.ipynb`) loads the course data, cleans titles, and uses Sentence-BERT to generate semantic embeddings for each course. These are saved for fast API use.
2. **FastAPI Backend**: `app.py` loads the model, embeddings, and data. It exposes a `/recommend` endpoint that takes a user query, computes its embedding, and returns the most similar courses.
3. **Express Server**: `mern/server/index.js` proxies frontend requests to FastAPI, handles user registration/login/history (MongoDB), and provides a `/api/gemini` endpoint for Gemini LLM queries.
4. **Frontend**: `mern/client/public/index.html` is a modern, responsive UI for login, registration, course recommendations, and Gemini LLM chat. All logic is in `app.js`.

---

## File-by-File Description

### Top Level

- **app.py**: FastAPI backend for course recommendations. Loads model, embeddings, and data at startup. Handles `/recommend` POST endpoint.
- **course_recommendation.ipynb**: Jupyter notebook for NLP, BERT, and embedding generation. Shows the full pipeline: data loading, cleaning, embedding, and recommendation logic.
- **course_title_embeddings.npy**: NumPy array of course title embeddings (generated by the notebook, used by FastAPI).
- **udemy_course_data.csv**: The dataset of courses (used by both notebook and API).
- **sentence_transformer_model/**: Directory containing the saved Sentence-BERT model files.

### mern/client/public/

- **index.html**: Main UI. Handles login, registration, recommendations, and Gemini LLM chat. Uses professional CSS and modern layout.
- **style.css**: All styles for the frontend, including responsive design and chat history scroll.
- **app.js**: Handles all frontend logic: authentication, recommendations, history, and Gemini LLM chat.

### mern/server/

- **index.js**: Express server. Proxies `/api/recommend` to FastAPI, handles user auth/history (MongoDB), and `/api/gemini` for Gemini LLM.
- **models/User.js**: Mongoose schema for user data and query history.
- **.env**: Environment variables (MongoDB URI, Gemini API key). **Never commit this file to public repos!**

---

## How to Run the Project

### 1. Start the FastAPI Backend

```sh
C:/Python313/python.exe -m uvicorn app:app --reload
```

- Runs at http://127.0.0.1:8000/

### 2. Start the Express Server

```sh
cd mern/server
npm install   # Only needed once
npm start
```

- Runs at http://localhost:5000/

### 3. Start the Frontend

```sh
cd mern/client
# If using plain HTML/JS: just open public/index.html in your browser
# If using npm for static server:
npm install   # Only needed once
npm start
```

- By default, open http://localhost:3000/ (if using npm), or open `public/index.html` directly.

---

## About the Jupyter Notebook (NLP & BERT)

- The notebook (`course_recommendation.ipynb`) demonstrates the full ML pipeline:
  - Loads and cleans course data
  - Uses Sentence-BERT to generate embeddings
  - Saves model and embeddings for API use
  - Implements the same recommendation logic as the API
  - (Optionally) zips the model for deployment
- You can use this notebook to retrain or update your model/embeddings as your data grows.

---

## Notes

- The `src/` folder in `client/` is not needed for this project and can be deleted.
- All environment variables (Mongo URI, Gemini API key) are stored in `mern/server/.env`.
- The Gemini LLM integration is via a secure backend proxy, so your API key is never exposed to the frontend.
- For production, always restrict your API keys and secure your environment files.

---

## Credits

- Built with FastAPI, Node.js/Express, MongoDB, Sentence-BERT, and Gemini LLM.
- UI design inspired by modern SaaS dashboards.
